{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9318b4bc",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Finally we get to the good stuff. We will use linear regression which will probably suck, Adaboost which I have absolutely no underestanding of (apparently widely used for time series forecasting), and lgbm which I actually did some research on. I expect linear to be awful but hey, noone said this project has to win the competition that has been closed for like 2 years anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabd871",
   "metadata": {},
   "source": [
    "### WRMSSE Calculation\n",
    "As mentioned in notebook 1, these metrics will be used to determine our models score.\n",
    "Big thanks to sakami for this implementation:\n",
    "https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834\n",
    "\n",
    "Note that due to having a competition leaderboard, we will forgo making a baseline model in lieu of a simple score comparison.\n",
    "\n",
    "I will also refrain from reformatting the results into the proper submission format as there is nothing to submit anyway. The WRMSSE scores should be good enough to judge the models, I might go back to this and add it later, but for now this will have to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a219fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 0  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'state_id',\n",
    "            'store_id',\n",
    "            'cat_id',\n",
    "            'dept_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            'item_id',\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n",
    "        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt)\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n",
    "\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n",
    "            all_scores.append(lv_scores.sum())\n",
    "\n",
    "        return np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513af80",
   "metadata": {},
   "source": [
    "## Imports and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b80aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from downcast import reduce\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a852ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('df_train_final.pkl')\n",
    "valid = pd.read_pickle('df_valid_final.pkl')\n",
    "test = pd.read_pickle('df_test_final.pkl')\n",
    "\n",
    "train = train.reset_index().set_index('date')\n",
    "valid = valid.reset_index().set_index('date')\n",
    "test = test.reset_index().set_index('date')\n",
    "\n",
    "train = reduce(train)\n",
    "valid = reduce(valid)\n",
    "test = reduce(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38fed3",
   "metadata": {},
   "source": [
    "# Feature selection and final splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "385364a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n",
       "       'wm_yr_wk', 'wday', 'month', 'year', 'items_sold', 'sell_price',\n",
       "       'event_num', 'snap', 'weekend', 'season', 'item_id_label',\n",
       "       'dept_id_label', 'cat_id_label', 'store_id_label', 'state_id_label',\n",
       "       'lag_7', 'lag_28', 'lag_35', 'lag_42', 'lag_60', 'lag_360', 'rmean_7_7',\n",
       "       'rmean_28_7', 'rmean_35_7', 'rmean_42_7', 'rmean_60_7', 'rmean_360_7',\n",
       "       'rmean_7_28', 'rmean_28_28', 'rmean_35_28', 'rmean_42_28',\n",
       "       'rmean_60_28', 'rmean_360_28', 'rmean_7_35', 'rmean_28_35',\n",
       "       'rmean_35_35', 'rmean_42_35', 'rmean_60_35', 'rmean_360_35',\n",
       "       'rmean_7_42', 'rmean_28_42', 'rmean_35_42', 'rmean_42_42',\n",
       "       'rmean_60_42', 'rmean_360_42', 'rmean_7_60', 'rmean_28_60',\n",
       "       'rmean_35_60', 'rmean_42_60', 'rmean_60_60', 'rmean_360_60',\n",
       "       'rmean_7_360', 'rmean_28_360', 'rmean_35_360', 'rmean_42_360',\n",
       "       'rmean_60_360', 'rmean_360_360'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "822c2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused = ['index', 'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','wm_yr_wk','items_sold',]\n",
    "features = list(set(train.columns)-set(unused))\n",
    "target = ['items_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f577e6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rmean_35_28',\n",
       " 'rmean_42_35',\n",
       " 'lag_28',\n",
       " 'season',\n",
       " 'event_num',\n",
       " 'rmean_42_28',\n",
       " 'rmean_35_35',\n",
       " 'rmean_60_35',\n",
       " 'rmean_60_42',\n",
       " 'cat_id_label',\n",
       " 'lag_360',\n",
       " 'rmean_7_360',\n",
       " 'month',\n",
       " 'lag_42',\n",
       " 'rmean_42_360',\n",
       " 'rmean_42_60',\n",
       " 'state_id_label',\n",
       " 'lag_35',\n",
       " 'rmean_360_42',\n",
       " 'rmean_7_28',\n",
       " 'rmean_35_60',\n",
       " 'rmean_28_42',\n",
       " 'dept_id_label',\n",
       " 'year',\n",
       " 'rmean_28_7',\n",
       " 'rmean_42_42',\n",
       " 'sell_price',\n",
       " 'rmean_7_42',\n",
       " 'lag_7',\n",
       " 'rmean_360_28',\n",
       " 'lag_60',\n",
       " 'rmean_60_28',\n",
       " 'rmean_360_360',\n",
       " 'rmean_35_42',\n",
       " 'rmean_60_360',\n",
       " 'rmean_360_7',\n",
       " 'store_id_label',\n",
       " 'wday',\n",
       " 'rmean_60_60',\n",
       " 'rmean_360_35',\n",
       " 'rmean_28_28',\n",
       " 'rmean_42_7',\n",
       " 'rmean_60_7',\n",
       " 'rmean_35_7',\n",
       " 'rmean_28_35',\n",
       " 'rmean_7_60',\n",
       " 'rmean_360_60',\n",
       " 'snap',\n",
       " 'item_id_label',\n",
       " 'rmean_35_360',\n",
       " 'rmean_7_35',\n",
       " 'rmean_7_7',\n",
       " 'weekend',\n",
       " 'rmean_28_60',\n",
       " 'rmean_28_360']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5631d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_valid = valid[features]\n",
    "y_valid = valid[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf47a5",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression(n_job=7, normalize=True)\n",
    "regressor.fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
