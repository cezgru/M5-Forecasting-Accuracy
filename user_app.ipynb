{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c599d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This script doesnt make too much sense. The entire premise is to deploy a very specific competition submission.\n",
      "Nevertheless, this script will provide you with an array containing item sale predictions. Use it as you will.\n",
      "\n",
      "\n",
      "Word of warning: this program may fail due to memory constraints if the dataset is too large.\n",
      "As such, we recommend only using a small dateset for future predictions. \n",
      "Its not as if you will use it to predict years in advance.\n",
      "\n",
      "\n",
      "For clarification:\n",
      "\n",
      "Input: contains calendar sales and prices shops etc. for n days\n",
      "\n",
      "Output: predicts item sales for n days\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from downcast import reduce\n",
    "\n",
    "def create_predictions(directory):\n",
    "    calendar = pd.read_csv(f'{directory}/calendar.csv')\n",
    "    sales = pd.read_csv(f'{directory}/sales_train_evaluation.csv')\n",
    "    sell_prices = pd.read_csv(f'{directory}/sell_prices.csv')\n",
    "    \n",
    "    calendar = reduce(calendar)\n",
    "    sell_prices = reduce(sell_prices)\n",
    "    sales = reduce(sales)\n",
    "    sales_d = pd.melt(\n",
    "        sales_df,\n",
    "        id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\n",
    "        var_name='d',\n",
    "        value_name='items_sold').merge(calendar, on='d', how='left').merge(sell_prices, on=['store_id', 'item_id', 'wm_yr_wk'], how='left')\n",
    "    sales_d['event_num'] = (sales_d['event_name_1'].notna()).astype(int) + (sales_d['event_name_2'].notna()).astype(int)\n",
    "    sales_d.loc[sales_d['state_id'] == 'CA', 'snap'] = sales_d.loc[sales_d['state_id'] == 'CA']['snap_CA']\n",
    "    sales_d.loc[sales_d['state_id'] == 'TX', 'snap'] = sales_d.loc[sales_d['state_id'] == 'TX']['snap_TX']\n",
    "    sales_d.loc[sales_d['state_id'] == 'WI', 'snap'] = sales_d.loc[sales_d['state_id'] == 'WI']['snap_WI']\n",
    "    sales_d['snap'] = sales_d['snap'].astype(int)\n",
    "    sales_d['weekend'] = (sales_d['wday'] <= 2).astype(int)\n",
    "    sales_d['season'] = (sales_d['month'] / 3).astype(int)\n",
    "    sales_d['season'] = (sales_d['season'] % 4).astype(int)\n",
    "    c_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "\n",
    "    for c in c_features:\n",
    "        le = LabelEncoder()\n",
    "        sales_d[c+'_label'] = le.fit_transform(sales_d[c])\n",
    "    lags = [7, 28, 35, 42, 60, 360]\n",
    "    lag_columns = [f'lag_{lag}' for lag in lags] # name columns\n",
    "    for lag, lag_column in zip(lags, lag_columns):\n",
    "        sales_d[lag_column] = sales_d[['id',\"items_sold\"]].groupby('id')['items_sold'].shift(lag)\n",
    "    rolls = [7, 28, 35, 42, 60, 360]\n",
    "    for r in rolls:\n",
    "        for lag, lag_column in zip(lags, lag_columns):\n",
    "            sales_d[f'rmean_{lag}_{r}'] = sales_d[['id', lag_column]].groupby('id')[lag_column].transform(lambda x: x.rolling(r).mean())\n",
    "    unused = ['index', 'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','wm_yr_wk','items_sold',]\n",
    "    features = list(set(train.columns)-set(unused))\n",
    "    \n",
    "    X = sales_d[features]\n",
    "    \n",
    "    filename = 'lgbm_final.sav'\n",
    "    pickle.dump(lgb_reg, open(filename, 'wb'))\n",
    "    \n",
    "    return lgb_reg.predict(X)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('This script doesnt make too much sense. The entire premise is to deploy a very specific competition submission.')\n",
    "    print('Nevertheless, this script will provide you with an array containing item sale predictions. Use it as you will.\\n')\n",
    "    print('\\nWord of warning: this program may fail due to memory constraints if the dataset is too large.')\n",
    "    print('As such, we recommend only using a small dateset for future predictions. \\nIts not as if you will use it to predict years in advance.\\n')\n",
    "    print('\\nFor clarification:')\n",
    "    print('\\nInput: contains calendar sales and prices shops etc. for n days')\n",
    "    print('\\nOutput: predicts item sales for n days\\n')\n",
    "    directory = input('\\nPlease provide the path to the directory containing calendar.csv, sales_train_evaluation.csv, sell_prices.csv')\n",
    "    print(create_predictions(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6205e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4560257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
